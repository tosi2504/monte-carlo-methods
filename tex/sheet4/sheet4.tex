\documentclass[11pt, a4paper]{scrartcl}

\usepackage[left=3cm, right=3cm, top=3cm, bottom=3cm]{geometry}
\usepackage{graphicx}
\usepackage{array}
\usepackage{amsmath}


\newcommand{\git}{\mathbin{
  \mathchoice{/\mkern-6mu/}% \displaystyle
    {/\mkern-6mu/}% \textstyle
    {/\mkern-5mu/}% \scriptstyle
    {/\mkern-5mu/}}}% \scriptscriptstyle


\title{Monte Carlo Methods - Sheet 4}
\subtitle{Ising Model: Wolff algorithm}
\author{Tobias Sizmann}

\begin{document}
\maketitle
\textit{"Nonlocal" truely is a scary word for every physics student. What follows is usually a mess of summation and integration over variables and their primed counterparts. It is so scary that even one of the most gifted physicists - Albert Einstein - labeled it as "spooky". This is completely taken out of context and has nothing to do with what follows except for the word "nonlocal". But it produces an interesting anecdote - which is obviously the only purpose of this text.}
\section{Introduction}
    We have seen that the Metropolis algorithm suffers from a bad disease: Critical slowing down. This is intrinsic to all local algorithms due to the low probability of a single spin flip. The obvious solution is a nonlocal (\textit{scaaaary}) algorithm. And so the german physicist Ulli Wolff proposed the Wolff algorithm in 1989. Instead of flipping a single spin the algorithm builds a cluster and then flips the whole cluster at once. If the cluster mechanism is constructed properly, it satisfies detailed balance and the algorithm samples the desired probability distribution.
\section{The Wolff algorithm}
    In the special case of the Ising model the Wolff algorithm is defined by the following steps
    \begin{enumerate}
        \item Choose an initial spin site randomly. This is the first site of the cluster. It has spin $s_{initial}$.
        \item Whenever a spin is added to the cluster, consider all neighbors that have spin $s_{neighbor} = s_{initial}$ and are not yet part of the cluster. Add each of those neighbors to the cluster with a probability $P_{add} = 1 - \exp(-2 \beta J)$
    \end{enumerate}
    In terms of implementation the algorithm suggests the use of a ``first in first out'' data structure like a queue. It can be shown that this algorithm satisfies detailed balance. Note that the time complexity for one cluster flip at maximum is in the order of one Metropolis sweep. In the introduction the claim has been made, that this algorithm is advantageous at the critical point. This can be seen immediately now: The probability to add an adjacent spin with same orientation to the cluster in the case of the Ising model at the critical point is $P_{add} = 1 - \exp(-2 \beta_c J) = 0.59$ which is rather large considering that for each added spin several new spins are considered (at least at the beginning of the cluster growth). Here an assumption has been made, however, namely that the density of adjacent spins with the same orientation is high. This is given physically: The spatial correlation length diverges at the critical point. We therefore expect the average cluster size $\langle n \rangle$ at the critical point to be way larger than one consequently reducing autocorrelation.
\section{Comparion: Wolff vs Metropolis}
    Goal of this section is to compare results of Wolff and Metropolis sample generation. Note that in terms of time complexity a Metropolis sweep always cost more or the same as a Wolff cluster flip. Therefore if the errors on estimates are lower for the Wolff algorithm than for Metropolis algorithm if the same amount of sweeps and cluster flips has been done, the Wolff algorithm proofs its superiority for this specific case of external parameters (here: temperature, lattice extend, coupling, external magnetic field). Be careful, as this argument does not work the other way around.

    All following discussions are done on a 64x64 grid with $J = 1$ and $M_{ext} = 0$ with 10000 thermalized sweeps/clusterflips. Metropolis samples from $T = 1$ to $T = 4$ with stepsize $\Delta T = 0.1$ have been generated. For the region $T = 2.1$ to $T = 2.4$ both Metropolis and Wolff samples have been generated with a stepsize of $\Delta T = 0.02$. The results are depicted in figures REF.
\end{document}
